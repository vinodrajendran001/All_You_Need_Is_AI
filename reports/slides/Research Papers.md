
# This Week's Top AI/ML Research Papers

#### Vinod

---

#### Transformers without normalization

<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; align-items: center;">
  <div>
    <p>Transformers can achieve or surpass normalized performance using a simple technique called Dynamic Tanh (DyT), replacing normalization layers with an element-wise operation inspired by tanh-like mappings observed in layer norm, validated across various tasks in computer vision and LLMs.</p>
  </div>
  <div>
    <img src="Pasted image 20250325101836.png" style="width: 100%; height: auto;">
  </div>
</div>






