
# This Week's Top AI/ML Research Papers

#### Vinod

---

#### Transformers without normalization


<grid drag="60 55" drop="5 10" >
`Transformers can achieve or surpass normalized performance using a simple technique called Dynamic Tanh (DyT), replacing normalization layers with an element-wise operation inspired by tanh-like mappings observed in layer norm, validated across various tasks in computer vision and LLMs.`
</grid>

<grid drag="25 55" drop="-5 10" style=bg="green">
25 x 55
</grid>





![[Pasted image 20250325101836.png]]