## 27.02.2025

- [A guide to JAX for PyTorch developers | Google Cloud Blog](https://cloud.google.com/blog/products/ai-machine-learning/guide-to-jax-for-pytorch-developers)
- [deeptutor.knowhiz.us/upload](https://deeptutor.knowhiz.us/upload) - Paper reading assistant with deeper understanding.
- [phind](https://www.phind.com/) - A visual search engine
- [geekan/MetaGPT: 🌟 The Multi-Agent Framework: First AI Software Company, Towards Natural Language Programming](https://github.com/geekan/MetaGPT) - MetaGPT helps you transform a single-line requirement into detailed user stories, competitive analyses, requirements, data structures, APIs, and documentation. It assigns roles like product manager, architect, project manager, and engineer to AI agents, simulating a software company's workflow.
- [NirDiamant/GenAI_Agents: This repository provides tutorials and implementations for various Generative AI Agent techniques, from basic to advanced. It serves as a comprehensive guide for building intelligent, interactive AI systems.](https://github.com/NirDiamant/GenAI_Agents)- This repository helps you develop Generative AI agents, from simple conversational models to complex multi-agent systems. It provides step-by-step tutorials, ready-to-use implementations, and documentation. It covers agent architectures, practical applications, and real-world deployment.

## 07.03.2025

- [ExplainGithub](https://link.mail.beehiiv.com/ss/c/u001.P5VhhHEXt9ALLSlwafYXZDsZ5nkBYN111z4zMhLNbpvvStaH_RVxXoFakxZmYQnHCIysNPji6-U9OVbW36ojnyT6_Gm6GmAQCaI5xs_8xHTUlGLUg56QWf9mOo06AU9y-lDyk6WO4zOigEa-3GXmYYRBuYdJKdtGXm9a4UEvhzecq3CKkAEBtMMSPJ6JJgDinB8L_Ma_zaKhD1UpZD1bYMLfnSRdLPHm6assuHrM5fzWAcNyNd39kht_yYl7lQY9/4ek/QMyLH5BEROS9uD9EUJjc7w/h26/h001.OKxVLlY9xOO6ID11sN7t-u7zC9D-eTExoTcBglzTAjM "https://link.mail.beehiiv.com/ss/c/u001.P5VhhHEXt9ALLSlwafYXZDsZ5nkBYN111z4zMhLNbpvvStaH_RVxXoFakxZmYQnHCIysNPji6-U9OVbW36ojnyT6_Gm6GmAQCaI5xs_8xHTUlGLUg56QWf9mOo06AU9y-lDyk6WO4zOigEa-3GXmYYRBuYdJKdtGXm9a4UEvhzecq3CKkAEBtMMSPJ6JJgDinB8L_Ma_zaKhD1UpZD1bYMLfnSRdLPHm6assuHrM5fzWAcNyNd39kht_yYl7lQY9/4ek/QMyLH5BEROS9uD9EUJjc7w/h26/h001.OKxVLlY9xOO6ID11sN7t-u7zC9D-eTExoTcBglzTAjM") > Turn hours of code reading into minutes of understanding.
- [MLOps python package](https://github.com/fmind/mlops-python-package) - Kickstart your MLOps initiative with a flexible, robust, and productive Python package.
- **[TAID: A Novel Method for Efficient Knowledge Transfer from Large Language Models to Small Language Models](https://substack.com/redirect/d3c1d03e-ada9-4d41-b406-787df40ffb26?j=eyJ1IjoiMTg2bzVvIn0.-AuoIYywR1ZESApp8FJseCWwCCZIKj8CtVTdemeZC-Q "https://substack.com/redirect/d3c1d03e-ada9-4d41-b406-787df40ffb26?j=eyJ1IjoiMTg2bzVvIn0.-AuoIYywR1ZESApp8FJseCWwCCZIKj8CtVTdemeZC-Q")**

## 12.03.2025

## Learnings

1. 15 Mind-Blowing AI Statistics Everyone Must Know About Now 

	- [**34 million**](https://amitkumar2211.medium.com/fun-fact-ai-creates-about-34-million-images-every-single-day-99a7bbd0fd63) **AI-Generated Images Created Daily**
	- [**71%**](https://artsmart.ai/blog/ai-image-generator-market-statistics/) **Of Social Media Images Now AI-Generated**
	- **Deepfake Fraud Attempts Surge To** [**6.5%**](https://www.insurancetimes.co.uk/news/fraud-attempts-with-deepfakes-surge-over-last-three-years/1454509.article) **Worldwide**
	- **Tech Giants Investing** [**$320 Billion**](https://www.businessinsider.com/big-tech-ai-capex-spend-meta-google-amazon-microsoft-earnings-2025-2) **In AI Development For 2025**
	- **Global AI Services Market To Reach** [**$243 Billion**](https://www.statista.com/outlook/tmo/artificial-intelligence/worldwide) **This Year**
	- [**97%**](https://www.ey.com/en_us/newsroom/2024/12/ey-research-artificial-intelligence-investments-set-to-remain-strong-in-2025-but-senior-leaders-recognize-emerging-risks) **Of Leaders Investing In AI Report Positive Return On Investment**
	- [**25%**](https://www.deloitte.com/global/en/about/press-room/deloitte-globals-2025-predictions-report.html) **Of Enterprises Will Deploy AI Agents This Year**
	- **Healthcare AI Market Valued At** [**$38.7**](https://explodingtopics.com/blog/ai-market-size-stats) **Billion, Doubling Since 2023**
	- **Adoption Gap:** [**81%**](https://www.businessinsider.com/ai-adoption-worker-survey-big-tech-spending-2025?utm_source=chatgpt.com) **Of Workers Still Not Using AI Tools**
	- **Trust Divide: AI** [**Acceptance**](https://www.axios.com/2025/02/13/trust-ai-china-us) **High In India (77%) and China (72%), Low In America ((32%)**
	- **AI Influencer Economy Approaching** [**$7 Billion**](https://artsmart.ai/blog/ai-influencer-statistics/) **Valuation**
	- **Data Centers To Consume** [**5%**](https://www.mckinsey.com/featured-insights/sustainable-inclusive-growth/charts/ais-power-binge) **Of U.S. Power, Doubling By 2030**
	- [**30%**](https://www.deloitte.com/global/en/about/press-room/deloitte-globals-2025-predictions-report.html) **Of New Smartphones To Feature On-Device GenAI**
	- [**50%**](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/tech-forward/open-source-in-the-age-of-ai) **Of Companies That Use AI Incorporate Open-Source Solutions**
	- **Nearly Half Of Tech Leaders (**[**49%**](https://www.pwc.com/us/en/tech-effect/ai-analytics/ai-predictions.html)**) Say AI Is Now Fully Integrated Into Business Strategy**
2. [Open R1 for Students - Hugging Face NLP Course](https://huggingface.co/learn/nlp-course/en/chapter12/1)
3. Reinforcement Learning Course
	- [Watch video](https://www.youtube.com/watch?v=ZHMWHr9811U&list=PLEhdbSEZZbDaFWPX4gehhwB9vJZJ1DNm8&index=3)
	- [Github](https://github.com/MathFoundationRL/Book-Mathematical-Foundation-of-Reinforcement-Learning)

![[Pasted image 20250312133027.png]]

## 13.03.2025

![[Pasted image 20250313230642.png]]


**

From my 12+ years of experience as a full-stack developer, working at Fortune 500 companies like PayPal and many other startups, I’ve gathered valuable insights that have helped me succeed in solving complex problems during coding interviews. Here’s what I’ve learned:

### 1. If the Input Array is Sorted

When you are given a sorted array, there are two go-to techniques that will make your job easier:

#### Binary Search

-   When to use it: Binary search is the optimal solution for searching for an element or solving problems related to finding a position in a sorted array.
    
-   How it works: Binary search works by repeatedly dividing the search interval in half. It starts by comparing the target value to the element in the middle. If they are not equal, it eliminates half of the search space.
    
-   Key advantage: It operates in O(log n) time complexity, which is much faster than a linear scan (O(n)).
    

#### Two Pointers

-   When to use it: If the problem asks to find pairs or elements satisfying certain conditions (e.g., sum equals to a target), two pointers is your best choice for a sorted array.
    
-   How it works: You initiate two pointers—one starting from the beginning of the array and the other from the end—and move them toward each other based on the condition you're trying to satisfy.
    
-   Key advantage: The time complexity of this approach is O(n), and it's very efficient for problems involving pairs or finding relationships between elements in sorted arrays.
    

---

### 2. If Asked for All Permutations/Subsets

When you're asked to generate all permutations or subsets of a given set, the solution is usually based on backtracking.

#### Backtracking

-   When to use it: Backtracking is a powerful technique for solving problems where you have to explore all possibilities or combinations in a constrained space, like generating all permutations or subsets.
    
-   How it works: It involves exploring a potential solution space by building solutions incrementally, then abandoning a solution as soon as it is determined that it cannot be extended to a valid solution (this is known as "pruning").
    
-   Key advantage: This method ensures you explore all possible combinations or permutations and works efficiently by reducing the search space through pruning.
    

---

### 3. If Given a Tree

When you're working with a tree, whether it's a binary tree or a general tree, there are two main strategies you should consider: Depth-First Search (DFS) and Breadth-First Search (BFS).

#### DFS

-   When to use it: DFS is most useful when you need to explore all possible paths (e.g., for finding paths, maximum depths, or solving tree traversal problems).
    
-   How it works: DFS explores as deep as possible down a branch before backtracking. It can be implemented recursively or using a stack.
    
-   Key advantage: It allows you to explore deeply nested nodes and works well for problems like pathfinding or tree traversal.
    

#### BFS

-   When to use it: BFS is ideal for level-order traversals, finding the shortest path in unweighted graphs, or problems where you need to explore nodes level by level.
    
-   How it works: BFS explores all neighbors of a node at the present depth level before moving on to nodes at the next depth level.
    
-   Key advantage: BFS guarantees that you find the shortest path in an unweighted graph and is useful for problems that require finding nodes at a certain level.
    

---

### 4. If Given a Graph

Graphs, whether directed, undirected, weighted, or unweighted, require two basic traversal techniques:

#### DFS

-   When to use it: Use DFS when you need to explore all possible paths in a graph (like finding connected components or cycles).
    
-   How it works: DFS can be implemented recursively or with an explicit stack. It explores deeper into the graph before backtracking.
    
-   Key advantage: It's suitable for problems where deep exploration is needed, such as topological sorting or cycle detection.
    

#### BFS

-   When to use it: BFS is best when you're looking for the shortest path, level-order traversal, or connected components.
    
-   How it works: BFS uses a queue to explore nodes level by level. It’s optimal for problems where the shortest path or level information is important.
    
-   Key advantage: BFS guarantees finding the shortest path in an unweighted graph and is ideal for problems like shortest-path algorithms.
    

---

### 5. If Given a Linked List

When given a linked list, two pointers is the most efficient technique.

#### Two Pointers

-   When to use it: Two pointers are used for problems such as detecting cycles in a linked list, finding the middle node, or reversing a linked list.
    
-   How it works: You initialize two pointers—slow and fast—where the slow pointer advances one step at a time, and the fast pointer advances two steps. This is helpful in problems involving the middle of a list or detecting loops.
    
-   Key advantage: This approach reduces time complexity and works effectively for problems requiring traversal with conditions on the steps.
    

---

### 6. If Recursion is Banned

Recursion can often be replaced by using a stack to simulate the recursion process.

#### Stack

-   When to use it: Use a stack to replace recursion for problems like depth-first search or when the recursive solution leads to a stack overflow due to deep recursion.
    
-   How it works: You maintain a stack of nodes or elements to process, and the algorithm processes them in a controlled, iterative manner.
    
-   Key advantage: It helps avoid the pitfalls of deep recursion and stack overflows while achieving the same result.
    

---

### 7. If You Must Solve In-Place

If the problem requires in-place operations, meaning you cannot use extra memory, you’ll rely on techniques like swapping values or storing multiple values in a single pointer.

#### Swap Corresponding Values

-   When to use it: This is useful for problems like reversing an array or swapping elements to solve problems like sorting.
    
-   How it works: You swap two values in-place without needing extra space.
    
-   Key advantage: It minimizes space complexity to O(1) while performing the operation efficiently.
    

#### Store Multiple Values in the Same Pointer

-   When to use it: This is typically used in problems like sorting or rearranging arrays where you can overwrite existing values as you progress.
    
-   How it works: You can overwrite or re-use memory locations to store intermediate values, which reduces memory usage.
    
-   Key advantage: It saves space and allows in-place modification of data structures.
    

---

### 8. If Asked for Maximum/Minimum Subarray/Subset/Options

Dynamic programming (DP) is your go-to approach for solving these problems efficiently.

#### Dynamic Programming

-   When to use it: DP is used for problems where the problem can be broken down into overlapping subproblems that can be solved optimally. It’s particularly useful for problems involving finding the maximum or minimum values in a sequence.
    
-   How it works: DP stores intermediate results to avoid redundant calculations. It can be implemented in both bottom-up (iterative) or top-down (recursive with memoization) approaches.
    
-   Key advantage: DP reduces time complexity from exponential to polynomial time in many cases, which makes it ideal for optimization problems.
    

---

### 9. If Asked for Top/Least K Items

For problems where you need to find the top K or least K elements, heaps or QuickSelect are the most efficient choices.

#### Heap

-   When to use it: Heaps are optimal for finding the k-th largest or smallest elements in an unsorted list.
    
-   How it works: A heap is a binary tree where each parent node is either larger or smaller than its child nodes. For top K or least K elements, a heap can be used to efficiently extract the largest or smallest elements.
    
-   Key advantage: Heaps provide an O(log n) time complexity for insertions and deletions, making them efficient for dynamic data.
    

#### QuickSelect

-   When to use it: QuickSelect is an efficient algorithm for finding the k-th largest or smallest element without fully sorting the array.
    
-   How it works: QuickSelect partitions the array and selects a subset of elements to recursively find the desired element in O(n) time on average.
    
-   Key advantage: QuickSelect is faster than sorting the entire array when you only need to find the k-th element.
    

---

### 10. If Asked for Common Strings

For problems that involve finding common strings or substrings, maps or tries are the best solutions.

#### Map

-   When to use it: A hash map can be used to track occurrences of strings, helping find common substrings or strings with certain properties.
    
-   How it works: You store the string’s frequency or occurrence in a map, and then easily retrieve values based on certain conditions.
    
-   Key advantage: Maps provide O(1) time complexity for lookups, making them highly efficient for these problems.
    

#### Trie

-   When to use it: A Trie is optimal for problems involving string matching or prefix-based queries.
    
-   How it works: A Trie is a tree-like data structure used for storing a dynamic set of strings, which is useful for finding common substrings or prefixes.
    
-   Key advantage: It allows for fast lookups and prefix-based searches in O(n) time complexity.
    

---

### 11. General Strategy

For problems not falling under any specific category, you can often use maps/sets for O(1) time complexity and O(n) space, or sorting for O(n log n) time complexity and O(1) space (depending on the problem).

#### Maps/Sets

-   When to use it: Maps and sets are used to store unique elements or key-value pairs. These structures give you efficient access to elements and allow you to check for membership in constant time.
    
-   Key advantage: They provide fast operations for insertion, deletion, and lookup, making them ideal for many problems involving unique elements or memberships.
    

#### Sorting

-   When to use it: Sorting is useful when you need to reorder data to apply algorithms like binary search or when working with problems like finding the kth smallest/largest element.
    
-   Key advantage: Sorting provides a way to convert a complex problem into a more manageable one, and many algorithms like binary search work well with sorted data.
    


## 14.03.2025

**Can Zenoh revive Autonomous Vehicle Platooning?**

First what is Autonomous Vehicle Platooning?

**Rather than having a fleet of autonomous vehicles;** you have ONE autonomous vehicle that acts as a "master", and other "automated" vehicles that act as followers.

**Imagine a convoy of trucks**, where the first truck has all the sensors and intelligence, and communicates the instructions to its followers that then "break" or steer the vehicle.

This is platooning, a leader — and followers.

**There are tons of theoretical advantages to using a platooning solution:** reduced drag, shortest distance, no need to equip the entire fleet of truck with LiDARs, ...

And it works like this:

![[Pasted image 20250314090914.png]]

The problem is, it never really worked.  
It can work from a "prototype" perspective, but (to my knowledge) I don't think the autonomous truck world ever adopted platooning as a solution.

**One of the reasons is latency**. You can't risk sending a "break" instruction 1 second too late when a convoy of trucks drive at 90 km/h. It's way too risky.

So what could you do?  
  
**You could try and reduce that communication latency.**

**Zenoh?**

Sounds both Biblical & Star Wars like.  
  
Whoever named it is a genius.  
  
And what is it? It's a better middleware for ROS.

**ROS— a very brief definition would be**: ROS is a middleware framework that helps algorithms communicate. We can have an object detector receiving images from multiple cameras and forwarding objects to a Trajectory Planner. It's turning independent algorithms into a system.

To explain why Zenoh is a good idea, let me share a simple graph decomposing ROS into 4 main parts: Nodes, Tools, Robotics, and Ecosystem.

![[Pasted image 20250314090710.png]]

According to this:

- ROS = Nodes Management + Robotics Customization + Tools + Ecosystem

But the "nodes" part is NOT really ROS. It's a standard protocol, like TCP for ROS1, and something called DDS for ROS2.

**And what is Zenoh? A replacement for TCP and DDS in the "Nodes" part.**

This means when you use it, nothing visibly changes: you still have Gazebo, messaging, etc... but under the hood, the protocol changes communication.

**This is an under-the-hood modification.**

**But it's very powerful, because while DDS (what ROS2 uses by default) was built for wired robotics, Zenoh is built for wireless robotics.**

And when you replace the default ROS protocol, you turn a wired robot into a wireless robot.

**And I think this is a solution to revive autonomous vehicle Platooning...**

**But you could also enable tons of other wireless applications, like Fleet Navigation, Drone Delivery, V2X, and many others...**


## 17.03.2025

- [MLOps-Basics](https://github.com/graviraja/MLOps-Basics) - The goal of the series is to understand the basics of MLOps like model building, monitoring, configurations, testing, packaging, deployment, cicd, etc.

## 21.03.2025

- [Digital Hygiene](https://karpathy.bearblog.dev/digital-hygiene/) - A list of things you can do to live a secure digital life.
- [AI Blindspots](https://ezyang.github.io/ai-blindspots/) - A list of coding blindspots in large language models (focused on the Sonnet family).
- [Agent S2](https://www.simular.ai/agent-s2) -Agent S2: An Open, Modular, and Scalable Framework for Computer Use Agents
- [rkinas/cuda-learning: This repository is a curated collection of resources, tutorials, and practical examples designed to guide you through the journey of mastering CUDA programming. Whether you're just starting or looking to optimize and scale your GPU-accelerated applications.](https://github.com/rkinas/cuda-learning)

## 24.03.2025

- [GenAI Agents](https://github.com/NirDiamant/GenAI_Agents)
	It is a great resource for:  
	1/ learning  
	2/ building  
	3/ sharing AI Agents  
	  
	ranging from simple conversational bots to complex, multi-agent systems.  
	  
	Key features:  
	🎓 Learn to build GenAI agents from beginner to advanced levels  
	🧠 Explore a wide range of agent architectures and applications  
	📚 Step-by-step tutorials and comprehensive documentation  
	🛠️ Practical, ready-to-use agent implementations  
	🌟 Regular updates with the latest advancements in GenAI  
	🤝 Share your own agent creations with the community
	
- **Agentic RAG**
	𝗡𝗮𝘁𝗶𝘃𝗲 𝗥𝗔𝗚  
	In Native RAG, the most common implementation nowadays, the user query is processed through a pipeline that includes retrieval, reranking, synthesis, and generation of a response.  
		  
	This process leverages retrieval and generation-based methods to provide accurate and contextually relevant answers.  
	  
	𝗔𝗴𝗲𝗻𝘁𝗶𝗰 𝗥𝗔𝗚  
	Agentic RAG is an advanced, agent-based approach to question answering over multiple documents in a coordinated manner. It involves comparing different documents, summarizing specific documents, or comparing various summaries.  
	  
	Agentic RAG is a flexible framework that supports complex tasks requiring planning, multi-step reasoning, tool use, and learning over time.  
	  
	𝗞𝗲𝘆 𝗖𝗼𝗺𝗽𝗼𝗻𝗲𝗻𝘁𝘀 𝗮𝗻𝗱 𝗔𝗿𝗰𝗵𝗶𝘁𝗲𝗰𝘁𝘂𝗿𝗲  
	- Document Agents: Each document is assigned a dedicated agent capable of answering questions and summarizing within its own document.  
	  
	- Meta-Agent: A top-level agent manages all the document agents, orchestrating their interactions and integrating their outputs to generate a coherent and comprehensive response.  
	  
	𝗙𝗲𝗮𝘁𝘂𝗿𝗲𝘀 𝗮𝗻𝗱 𝗕𝗲𝗻𝗲𝗳𝗶𝘁𝘀  
	- Autonomy: Agents act independently to retrieve, process, and generate information.  
	  
	- Adaptability: The system can adjust strategies based on new data and changing contexts.  
	  
	- Proactivity: Agents can anticipate needs and take preemptive actions to achieve goals.  
	Applications  
	  
	Agentic RAG is particularly useful in scenarios requiring thorough and nuanced information processing and decision-making.  
	  
	A few days ago, I discussed how the future of AI lies in AI Agents. RAG is currently the most popular use case, and with an agentic architecture, you will supercharge RAG!
	![[Pasted image 20250324192032.png]]

## 25.03.2025

- Last 2 week's top AI/ML research papers:
	- Transformers without Normalization 
	- Block Diffusion 
	- Compute Optimal Scaling of Skills 
	- DAPO: An OS LLM RL System at Scale 
	- Teaching LLMs How to Learn with Contextual Fine-Tuning 
	- GR00T N1 - Why the Brain Cannot Be a Digital Computer 
	- RWKV-7 "Goose" with Expressive Dynamic State Evolution 
	- Why Do Multi-Agent LLM Systems Fail? 
	- Chain-of-Thought Reasoning In The Wild Is Not Always Faithful 
	- Light-R1 
	- Where do Large Vision-Language Models Look at when Answering Questions? 
	- Improving Planning of Agents for Long-Horizon Tasks 
	- UniCombine 
	- How much do LLMs learn from negative examples? 
	- Tokenize Image as a Set 
	- Search-R1 
	- Measuring AI Ability to Complete Long Tasks 
	- Does Your VLM Get Lost in the Long Video Sampling Dilemma? 
	- Unified Autoregressive Visual Generation and Understanding with Continuous Tokens
	- Personalize Anything for Free with Diffusion Transformer 
	- The KoLMogorov Test: Compression by Code Generation 
	- Optimizing ML Training with Metagradient Descent
	- DeepMesh 
	- Thinking Machines 
	- A Review of DeepSeek Models 
	- A Survey on Efficient Reasoning 
	- Agentic Memory for LLM Agents
- [GenAI-Showcase/notebooks/agents at main · mongodb-developer/GenAI-Showcase](https://github.com/mongodb-developer/GenAI-Showcase/tree/main/notebooks/agents) - Jupyter Notebooks demonstrating how to build AI agents using various frameworks and MongoDB Atlas as the vector store and memory provider.
- Which Agentic Framework should I use?
![[Pasted image 20250325113120.png]]

## 27.03.2025

- [n8n-io/n8n: Fair-code workflow automation platform with native AI capabilities. Combine visual building with custom code, self-host or cloud, 400+ integrations.](https://github.com/n8n-io/n8n?tab=readme-ov-file) - n8n is a workflow automation platform that gives technical teams the flexibility of code with the speed of no-code. With 400+ integrations, native AI capabilities, and a fair-code license, n8n lets you build powerful automations while maintaining full control over your data and deployments.
- [The Future of AI Agents is Event-Driven | by Sean Falconer | Mar, 2025 | Medium](https://seanfalconer.medium.com/the-future-of-ai-agents-is-event-driven-9e25124060d6)

## 28.03.2025

- Alibaba [released](https://qwenlm.github.io/blog/qwen2.5-omni/) Qwen2.5-Omni-7B, a new multimodal AI capable of processing text, images, audio, and video simultaneously while being efficient enough to run directly on consumer hardware like smartphones and laptops.
- The [Model context protocol](https://modelcontextprotocol.io/introduction) (aka MCP) is a way to provide tools and context to the LLM. From the MCP docs:
	```Quote
	MCP is an open protocol that standardizes how applications provide context to LLMs. Think of MCP like a USB-C port for AI applications. Just as USB-C provides a standardized way to connect your devices to various peripherals and accessories, MCP provides a standardized way to connect AI models to different data sources and tools.
	```
	- [https://blog.dailydoseofds.com/p/visual-guide-to-model-context-protocol](Visual Guide to Model Context Protocol (MCP))
	![[Pasted image 20250409095957.png]]
- [microsoft/playwright-mcp: Playwright Tools for MCP](https://github.com/microsoft/playwright-mcp?tab=readme-ov-file) is a Model Context Protocol (MCP) server that enables large language models to interact with web pages using Playwright, bypassing the need for screenshots or visually-tuned models.

## 30.03.2025

- [NVIDIA Dynamo](https://github.com/ai-dynamo/dynamo) is a high-throughput low-latency inference framework designed for serving generative AI and reasoning models in multi-node distributed environments.

## 01.04.2025

- [Dell and NVIDIA explaining the value of local GPU compute across all industries](https://reshaping-workflows.simplecast.com/episodes)
- Anthropic just unlocked an AI’s brain, and found at least _six_ things you'll want to know…
	1. Plans rhyming words [in advance](https://link.mail.beehiiv.com/ss/c/u001.26HABC69RFxgG0sCL9wUtUTCunQDlTDJnWZQtYYHujvlSi094Ya1OX4Cz2m6pIZFrxwrjYIzqBfG5gyKQ0BeNuK27cpvY6O2nOGeQk6CP09YJVuC3-5MuQ5DDpKrVcac0X_KfCAdShZnQDWyni3H8zbu_jduAnkaidZiNeOzTU1_CVIA-W_7hr6mPEA9Ont_tIQ3Y1fiuvY10vzy6NS7sbYCvOCd-k0dD_hTnJ-iuogeI74BQRJXXX7yEUuSZlsf6vk6w-pxKileAUuklE4-0XcA6K6w4pGoIXg6JVCqzmZXwznrOdGuVdi38a3fAFK6R-6kuhcvJh_wwiMUzfrjrRuIKUC8mvtC73b2sdqqBS8zlKz-O7RXBUHagVWTCQLTnAgUdeVWSyDHbUZoyF-wzPPLDpXOyUp5nkfFp2lAuCCEOwIvrUnrWQG-9d8bGDO-/4f8/HfnPeI7iQMiS7OQQ_N5TFg/h12/h001.ZXRw5vzJVVVWoT4qrVVHw03K7UAEXBjAaIoLZ8i1QJg "https://link.mail.beehiiv.com/ss/c/u001.26HABC69RFxgG0sCL9wUtUTCunQDlTDJnWZQtYYHujvlSi094Ya1OX4Cz2m6pIZFrxwrjYIzqBfG5gyKQ0BeNuK27cpvY6O2nOGeQk6CP09YJVuC3-5MuQ5DDpKrVcac0X_KfCAdShZnQDWyni3H8zbu_jduAnkaidZiNeOzTU1_CVIA-W_7hr6mPEA9Ont_tIQ3Y1fiuvY10vzy6NS7sbYCvOCd-k0dD_hTnJ-iuogeI74BQRJXXX7yEUuSZlsf6vk6w-pxKileAUuklE4-0XcA6K6w4pGoIXg6JVCqzmZXwznrOdGuVdi38a3fAFK6R-6kuhcvJh_wwiMUzfrjrRuIKUC8mvtC73b2sdqqBS8zlKz-O7RXBUHagVWTCQLTnAgUdeVWSyDHbUZoyF-wzPPLDpXOyUp5nkfFp2lAuCCEOwIvrUnrWQG-9d8bGDO-/4f8/HfnPeI7iQMiS7OQQ_N5TFg/h12/h001.ZXRw5vzJVVVWoT4qrVVHw03K7UAEXBjAaIoLZ8i1QJg") before writing poetry.
	2. Uses a universal “[language of thought](https://link.mail.beehiiv.com/ss/c/u001.26HABC69RFxgG0sCL9wUtUTCunQDlTDJnWZQtYYHujvlSi094Ya1OX4Cz2m6pIZFrxwrjYIzqBfG5gyKQ0BeNuK27cpvY6O2nOGeQk6CP09YJVuC3-5MuQ5DDpKrVcac0X_KfCAdShZnQDWyni3H8wp_WZMMlWBMDXMBUOBPn127FolrMh-Yn5RSm8ZouvQJu1T5OzHr1vcJ4d_0DSfLxcraB8wls7vwa0GakkRI-C_iRutY53QSeE2hO1dTSEyedXs3BogVIF8VO4CIhSvZWuEeVtA_pOEMV9QfRfjkwi-zAxh9IAqSB9iOWeGv7APWJO6nk5YKnu2ItCzUen98dmxx4dRHPVP69BkwNJMA4iphWit0OY5HNs67vZcgjrJpoFIa3W6wAly9T0Npeo1N82O5zBdRuhO96cgL_EaYqDb1NQqrYm90F7gUmlUWY6LZ/4f8/HfnPeI7iQMiS7OQQ_N5TFg/h13/h001.ImkCa7Fvui4pNiTTu5ICqfo9ae6H51UCOMJ_uiNJBsw "https://link.mail.beehiiv.com/ss/c/u001.26HABC69RFxgG0sCL9wUtUTCunQDlTDJnWZQtYYHujvlSi094Ya1OX4Cz2m6pIZFrxwrjYIzqBfG5gyKQ0BeNuK27cpvY6O2nOGeQk6CP09YJVuC3-5MuQ5DDpKrVcac0X_KfCAdShZnQDWyni3H8wp_WZMMlWBMDXMBUOBPn127FolrMh-Yn5RSm8ZouvQJu1T5OzHr1vcJ4d_0DSfLxcraB8wls7vwa0GakkRI-C_iRutY53QSeE2hO1dTSEyedXs3BogVIF8VO4CIhSvZWuEeVtA_pOEMV9QfRfjkwi-zAxh9IAqSB9iOWeGv7APWJO6nk5YKnu2ItCzUen98dmxx4dRHPVP69BkwNJMA4iphWit0OY5HNs67vZcgjrJpoFIa3W6wAly9T0Npeo1N82O5zBdRuhO96cgL_EaYqDb1NQqrYm90F7gUmlUWY6LZ/4f8/HfnPeI7iQMiS7OQQ_N5TFg/h13/h001.ImkCa7Fvui4pNiTTu5ICqfo9ae6H51UCOMJ_uiNJBsw")” across languages:
		1. When asked for antonyms in English, French, and Chinese, the same core features activate—with only the final output differing based on language.
	3. Solves [math problems](https://link.mail.beehiiv.com/ss/c/u001.26HABC69RFxgG0sCL9wUtUTCunQDlTDJnWZQtYYHujvlSi094Ya1OX4Cz2m6pIZFrxwrjYIzqBfG5gyKQ0BeNuK27cpvY6O2nOGeQk6CP09YJVuC3-5MuQ5DDpKrVcac0X_KfCAdShZnQDWyni3H81T9j8dbBfx5mMh1z7BNqCiUdAUfRlgGElYNI3tpvXG2DqpdCHnrIZLgGZSNM9phZ1PxzOJ33bpTyj53QpG8oWKtimePe_5xWiqHz-439yENLoiZ4Vyo8kJCQHHhYqO39P4KNAtawz8ZGazbM8lxO-mb1dvHA1dzarDsjboN3LFZvDI_tj6M2y58RWiOlWo489ZNxRmMkQCY2j78c5Ka-5m6VFukryPrM-lojIuESIxjZkcWQzVcVkP92HPjGlAfCXbF-P0eYV08JgXZr3KbC3Dk-Ik9ZjW-2ZgLfHHcqgx6/4f8/HfnPeI7iQMiS7OQQ_N5TFg/h14/h001.iR39sy-nvYBJLlXfmdoyQEfkM1NbEHphJ1VpyC8ymI8 "https://link.mail.beehiiv.com/ss/c/u001.26HABC69RFxgG0sCL9wUtUTCunQDlTDJnWZQtYYHujvlSi094Ya1OX4Cz2m6pIZFrxwrjYIzqBfG5gyKQ0BeNuK27cpvY6O2nOGeQk6CP09YJVuC3-5MuQ5DDpKrVcac0X_KfCAdShZnQDWyni3H81T9j8dbBfx5mMh1z7BNqCiUdAUfRlgGElYNI3tpvXG2DqpdCHnrIZLgGZSNM9phZ1PxzOJ33bpTyj53QpG8oWKtimePe_5xWiqHz-439yENLoiZ4Vyo8kJCQHHhYqO39P4KNAtawz8ZGazbM8lxO-mb1dvHA1dzarDsjboN3LFZvDI_tj6M2y58RWiOlWo489ZNxRmMkQCY2j78c5Ka-5m6VFukryPrM-lojIuESIxjZkcWQzVcVkP92HPjGlAfCXbF-P0eYV08JgXZr3KbC3Dk-Ik9ZjW-2ZgLfHHcqgx6/4f8/HfnPeI7iQMiS7OQQ_N5TFg/h14/h001.iR39sy-nvYBJLlXfmdoyQEfkM1NbEHphJ1VpyC8ymI8") like [humans do](https://link.mail.beehiiv.com/ss/c/u001.26HABC69RFxgG0sCL9wUtUTCunQDlTDJnWZQtYYHujvlSi094Ya1OX4Cz2m6pIZFrxwrjYIzqBfG5gyKQ0BeNuK27cpvY6O2nOGeQk6CP09YJVuC3-5MuQ5DDpKrVcac0X_KfCAdShZnQDWyni3H8_3KF3LYh-XCsd5WEccjKIQx3ua5ZH6V57A95-j-A1mHBgnB-HyHxBW0iqZpZ_YbQq4D6JIK8PM5JuBcIfhmHEtnUGjcl_TtioMg9BObZAiyppUY0iwZb_Jn9Rw3fVHCkKv9gEpbrcRPqvkOhzhDPXNzqI8XYdtqNF4W0I5tkzH2421ckql6pFJxPvL69WzM-WBznIpI5TymfRVCZVWYzeQIvlT5JH3ArL-yTVMVXKPdikxh0rPB5wtICul_jGQ8XFyM7OHjs4cbWXMTzvtJ3J0KTChBPrT1WPAmyGQ-2krm/4f8/HfnPeI7iQMiS7OQQ_N5TFg/h15/h001.OEqceHtsFB250K5amJsptTjHqz41TJFXnyY4OwN5rY8 "https://link.mail.beehiiv.com/ss/c/u001.26HABC69RFxgG0sCL9wUtUTCunQDlTDJnWZQtYYHujvlSi094Ya1OX4Cz2m6pIZFrxwrjYIzqBfG5gyKQ0BeNuK27cpvY6O2nOGeQk6CP09YJVuC3-5MuQ5DDpKrVcac0X_KfCAdShZnQDWyni3H8_3KF3LYh-XCsd5WEccjKIQx3ua5ZH6V57A95-j-A1mHBgnB-HyHxBW0iqZpZ_YbQq4D6JIK8PM5JuBcIfhmHEtnUGjcl_TtioMg9BObZAiyppUY0iwZb_Jn9Rw3fVHCkKv9gEpbrcRPqvkOhzhDPXNzqI8XYdtqNF4W0I5tkzH2421ckql6pFJxPvL69WzM-WBznIpI5TymfRVCZVWYzeQIvlT5JH3ArL-yTVMVXKPdikxh0rPB5wtICul_jGQ8XFyM7OHjs4cbWXMTzvtJ3J0KTChBPrT1WPAmyGQ-2krm/4f8/HfnPeI7iQMiS7OQQ_N5TFg/h15/h001.OEqceHtsFB250K5amJsptTjHqz41TJFXnyY4OwN5rY8"):
		1. One part of Claude’s brain carefully counts the ones place (like knowing 6+9=15, so the answer ends in 5).
		2. While another roughly estimates the total (like “that's around 90-something”).
	4. forms [multi-hop reasoning](https://link.mail.beehiiv.com/ss/c/u001.26HABC69RFxgG0sCL9wUtUTCunQDlTDJnWZQtYYHujvlSi094Ya1OX4Cz2m6pIZFrxwrjYIzqBfG5gyKQ0BeNuK27cpvY6O2nOGeQk6CP09YJVuC3-5MuQ5DDpKrVcac0X_KfCAdShZnQDWyni3H8zoCWLwt7S6TpitdZ_PLNMn-Vkqbn-2sdKNgGCIG4fJFnnjeVDcs0tugC5zK-ZsRKFBmNEA7wfeSEffTFbsCyHlKKPlgOlj9_NE-fDDIWmQiRcKOAIGaHoz1RDdgeEXtEZn8gF6aZNxXKqliz-XKk7snYQxYG5y1h410AeQvltww27n2YDJS4qoDU7J_wy_g8mrBwlxyqeq8ri74NP1SduLvG0bkhwUEsLZTWAhnUwpMvNLdz6Y1IGuwdtUU-NBTFXplUzWXlKNtNIy2sDOcynXsycwGyPsZlYR39Fo3DnSt/4f8/HfnPeI7iQMiS7OQQ_N5TFg/h16/h001.-MakCsNsISmT-XKQvYywdV6pK0toRF5Hm-SC3YGxP1I "https://link.mail.beehiiv.com/ss/c/u001.26HABC69RFxgG0sCL9wUtUTCunQDlTDJnWZQtYYHujvlSi094Ya1OX4Cz2m6pIZFrxwrjYIzqBfG5gyKQ0BeNuK27cpvY6O2nOGeQk6CP09YJVuC3-5MuQ5DDpKrVcac0X_KfCAdShZnQDWyni3H8zoCWLwt7S6TpitdZ_PLNMn-Vkqbn-2sdKNgGCIG4fJFnnjeVDcs0tugC5zK-ZsRKFBmNEA7wfeSEffTFbsCyHlKKPlgOlj9_NE-fDDIWmQiRcKOAIGaHoz1RDdgeEXtEZn8gF6aZNxXKqliz-XKk7snYQxYG5y1h410AeQvltww27n2YDJS4qoDU7J_wy_g8mrBwlxyqeq8ri74NP1SduLvG0bkhwUEsLZTWAhnUwpMvNLdz6Y1IGuwdtUU-NBTFXplUzWXlKNtNIy2sDOcynXsycwGyPsZlYR39Fo3DnSt/4f8/HfnPeI7iQMiS7OQQ_N5TFg/h16/h001.-MakCsNsISmT-XKQvYywdV6pK0toRF5Hm-SC3YGxP1I") (connecting Dallas → Texas → Austin) “in its head.”
     ![[Pasted image 20250401113558.png]]
     **They also found Claude** **sometimes tries to deceive its users when faced with conflicting goals:**
     - Claude maintains a “known entity” feature that represents whether it knows about a topic.
     - When Claude hallucinates, it's often because the “known entity” incorrectly activates on a topic it doesn’t fully understand (_same, bro)._
     - Apparently, Claude only recognizes and refuses harmful requests when it reaches the end of a sentence—explaining why some jailbreaks still work.
       
     **The researchers even caught Claude working backward from human-provided answers to fabricate plausible calculations (which they call this “[motivated reasoning](https://link.mail.beehiiv.com/ss/c/u001.26HABC69RFxgG0sCL9wUtUTCunQDlTDJnWZQtYYHujvlSi094Ya1OX4Cz2m6pIZFrxwrjYIzqBfG5gyKQ0BeNuK27cpvY6O2nOGeQk6CP09YJVuC3-5MuQ5DDpKrVcac0X_KfCAdShZnQDWyni3H8zWLizfIBbgaSY5UegipdVnhcTmKlVEliYaW6Q1oohufXBayfbRu4yTTp9RTpE0r28JejTJAI7qjS3F4uEBcHaZrNdEGTsZGT96uGrSlAaFrvTI8gRq4Ul_iEG2vpGkdT6bSxKR2hnPUTdF8zVj2sd6ErGhSy2gW9tA5qQMGLdXDu8eYtetcu71u4O4WTf2n76tfz6ZmZ0QyllS0E_hWvP25GWN1v3HQjFqLfOImul_Iv2qDdhSt99bZoF4ATDIheTjst_Sfs83okmOZt6SH-vG65V5cwryufFb0zfY2Jajz/4f8/HfnPeI7iQMiS7OQQ_N5TFg/h18/h001.jY4W7J8ui-i9xqSoFzM2C-9OeaefWK_Fd2KVqon9glI "https://link.mail.beehiiv.com/ss/c/u001.26HABC69RFxgG0sCL9wUtUTCunQDlTDJnWZQtYYHujvlSi094Ya1OX4Cz2m6pIZFrxwrjYIzqBfG5gyKQ0BeNuK27cpvY6O2nOGeQk6CP09YJVuC3-5MuQ5DDpKrVcac0X_KfCAdShZnQDWyni3H8zWLizfIBbgaSY5UegipdVnhcTmKlVEliYaW6Q1oohufXBayfbRu4yTTp9RTpE0r28JejTJAI7qjS3F4uEBcHaZrNdEGTsZGT96uGrSlAaFrvTI8gRq4Ul_iEG2vpGkdT6bSxKR2hnPUTdF8zVj2sd6ErGhSy2gW9tA5qQMGLdXDu8eYtetcu71u4O4WTf2n76tfz6ZmZ0QyllS0E_hWvP25GWN1v3HQjFqLfOImul_Iv2qDdhSt99bZoF4ATDIheTjst_Sfs83okmOZt6SH-vG65V5cwryufFb0zfY2Jajz/4f8/HfnPeI7iQMiS7OQQ_N5TFg/h18/h001.jY4W7J8ui-i9xqSoFzM2C-9OeaefWK_Fd2KVqon9glI").”).** - That means language models can appear to “reason”, when what they’re _actually_ doing is working backward from conclusions rather than following logical steps forward

## 02.04.2025

- [agno-agi/agno: A lightweight library for building Multimodal Agents. Give LLMs superpowers like memory, knowledge, tools and reasoning.](https://github.com/agno-agi/agno) - It helps you build multimodal AI agents that generate text, images, audio, and video. It runs 10,000x faster than LangGraph with 50x lower memory use. Agents use memory, tools, and reasoning. Support structured outputs, RAG via vector DBs, real-time monitoring, and multi-agent coordination. Works with any model or provider.

## 04.04.2025

- [MCP-Use](https://github.com/pietrozullo/mcp-use) is the open source way to connect any LLM to MCP tools and build custom agents that have tool access, without using closed source or application clients. 

## 09.04.2025

- [Browser MCP - MCP server for your browser](https://browsermcp.io/) Browser MCP allows users to connect AI apps to their browsers to automate tasks. Automation happens locally on users' machines, resulting in better performance without network latency. Browser activity stays on-device and isn't sent to remote servers. Browser MCP uses existing browser profiles, keeping users logged into all of their services. It avoids CAPTCHAs by using real browser fingerprints.
- If you were building a Q&A feature (or chatbot) based on very long documents (like books), what evals would you focus on?
	1. Two metrics 
		- **Faithfulness**: Grounding of answers in document's content. Not to be confused with correctness—an answer can be correct (based on updated information) but not faithful to the document. Sub-metric: Precision of citations  
		- **Helpfulness**: Usefulness (directly addresses the question with enough detail and explanation) and completeness (does not omit important details); an answer can be faithful but not helpful if too brief or doesn't answer the question  
		- Evaluate separately: Faithfulness = binary label -> LLM-evaluator; Helpfulness = pairwise comparisons -> reward model
	2. How to build robust evals
		- Use LLMs to generate questions from the text  
		- Evals should evaluate positional robustness (i.e., have questions at the beginning, middle, and end of text)
	3. Potential challenges  
		- Open-ended questions may have no single correct answer, making reference-based evals trickly. For example: What is the theme of this novel?  
		- Questions should be representative of prod traffic, with a mix of factual, inferential, summarization, definitional questions.
	4. Benchmark Datasets
		![[Pasted image 20250409093922.png]]

## 14.04.2025

- ### To make your OWN agent (to automate anything)
	- **The two main tools non-coders (and some coders) use to do this are** [**Make**]([Make | Automation Software | Connect Apps & Design Workflows | Make](https://www.make.com/en)) **and** [**n8N**]([Powerful Workflow Automation Software & Tools - n8n](https://n8n.io/))**.**
	- Make is the every man’s tool, while n8n is the coder’s preference (it’s kinda like the Claude to [Make.com]([Make | Automation Software | Connect Apps & Design Workflows | Make](https://www.make.com/en))’s ChatGPT—_all the cool kids use n8n).
	- **Tutorials:** 
		- [link 1](https://www.youtube.com/live/NUPjbWsSe7s)
		- [link 2](https://www.youtube.com/watch?v=yzvLfHb0nqE)
		- [link 3](https://www.youtube.com/watch?v=H0YRniHh2tg)


- ### NVIDIA AI Frameworks

![[Pasted image 20250414234447.png]]

 1️⃣ 𝗖𝗨𝗗𝗔  
Parallel computing platform and API to accelerate computation on NVIDIA GPUs.  
  
Keypoints:  
↳ Kernels - C/C++ functions.  
↳ Thread - executes the kernel instructions.  
↳ Block - groups of threads.  
↳ Grid - collection of blocks.  
↳ Streaming Multiprocessor (SM) - processor units that execute thread blocks.  
  
When a CUDA program invokes a kernel grid, the thread blocks are distributed to the SMs.  
  
CUDA follows the SIMT (Single Instruction Multiple Threads) architecture to execute threads logic and uses a Barrier to gather and synchronize Threads.  
  
2️⃣ 𝗰𝘂𝗗𝗡𝗡  
Library with highly tuned implementations for standard routines such as:  
↳ forward and backward convolution  
↳ attention  
↳ matmul, pooling, and normalization - which are used in all NN Architectures.  
  
3️⃣ 𝗧𝗲𝗻𝘀𝗼𝗿𝗥𝗧  
If we unpack a model architecture, we have multiple layer types, operations, layer connections, activations, etc. Imagine an NN architecture as a complex Graph of operations.  
  
TensorRT can:  
↳ Scan that graph  
↳ Identify bottlenecks  
↳ Optimize  
↳ Remove, merge layers  
↳ Reduce layer precisions,  
↳ Many other optimizations.  
  
4️⃣ 𝗧𝗲𝗻𝘀𝗼𝗿𝗥𝗧-𝗟𝗟𝗠  
Inference Engine that brings the TensorRT Compiler optimizations to Transformer-based models.  
  
Covers the advanced and custom requirements for LLMs, such as:  
↳ KV Caching  
↳ Inflight Batching  
↳ Optimized Attention Kernels  
↳Tensor Parallel  
↳ Pipeline Parallel.  
  
5️⃣ 𝗧𝗿𝗶𝘁𝗼𝗻 𝗜𝗻𝗳𝗲𝗿𝗲𝗻𝗰𝗲 𝗦𝗲𝗿𝘃𝗲𝗿  
An open source, high-performance, and secure serving system for AI Workloads. Devs can optimize their models, define serving configurations in Protobuf Text files, and deploy.  
  
It supports multiple framework backends, including:  
↳ Native PyTorch, TensorFlow  
↳ TensorRT, TensorRT-LLM  
↳ Custom BLS (Bussiness Language Scripting) with Python Backends  
  
6️⃣ 𝗡𝗩𝗜𝗗𝗜𝗔 𝗡𝗜𝗠  
Set of plug-and-play inference microservices that package up multiple NVIDIA libraries and frameworks highly tuned for serving LLMs to production cluster & datacenters scale.  
  
It has:  
↳ CUDA, cuDNN  
↳ TensorRT  
↳ Triton Server  
↳ Many other libraries - baked in.  
  
NIM provides the optimal serving configuration for an LLM.  
  
7️⃣ 𝗗𝘆𝗻𝗮𝗺𝗼 𝗜𝗻𝗳𝗲𝗿𝗲𝗻𝗰𝗲 𝗙𝗿𝗮𝗺𝗲𝘄𝗼𝗿𝗸  
The newest inference framework for accelerating and scaling GenAI workloads.  
  
Composed of modular blocks, robust and scalable.  
  
Implements:  
↳ Elastic compute - GPU Planner  
↳ KV Routing, Sharing, and Caching  
↳ Disaggregated Serving of Prefill and Decode.


## 21.04.2025

These 7 GitHub repos are the ones I always recommend:  
  
1. All algorithms implemented in Python (199k stars)  
	[https://lnkd.in/gdeUgjsi](https://lnkd.in/gdeUgjsi)  
  
2. Awesome Machine Learning (67.6k stars)  
	[https://lnkd.in/gSGVvmBB](https://lnkd.in/gSGVvmBB)  
  
3. Machine Learning interviews from FAANG (10.6k stars)  
	[https://lnkd.in/gBhPEN6f](https://lnkd.in/gBhPEN6f)  
  
4. Machine Learning cheat sheet (7.6k stars)  
	[https://lnkd.in/gHtehPv7](https://lnkd.in/gHtehPv7)  
  
5. Guide for ML / AI technical interviews (6k stars)  
	[https://lnkd.in/grGHzGqm](https://lnkd.in/grGHzGqm)  
  
6. Complete System Design (4.3k stars)  
	[https://lnkd.in/ggkqm9US](https://lnkd.in/ggkqm9US)  
  
7. 65 Machine Learning interview questions (3.4k stars)  
	[https://lnkd.in/g4b3T6xx](https://lnkd.in/g4b3T6xx)

## 22.04.2025

- 11 new types of RAG
	1. InstructRAG -> [InstructRAG: Leveraging Retrieval-Augmented Generation on Instruction Graphs for LLM-Based Task Planning (2504.13032)](https://huggingface.co/papers/2504.13032)  
	Combines RAG with a multi-agent framework, using a graph-based structure, an RL agent to expand task coverage, and a meta-learning agent for better generalization  
	  
	2. CoRAG (Collaborative RAG) -> [CoRAG: Collaborative Retrieval-Augmented Generation (2504.01883)](https://huggingface.co/papers/2504.01883)  
	A collaborative framework that extends RAG to settings where clients train a shared model using a joint passage store  
	  
	3. ReaRAG -> [ReaRAG: Knowledge-guided Reasoning Enhances Factuality of Large Reasoning Models with Iterative Retrieval Augmented Generation (2503.21729)](https://huggingface.co/papers/2503.21729)  
	It uses a Thought-Action-Observation loop to decide at each step whether to retrieve information or finalize an answer, reducing unnecessary reasoning and errors  
	  
	4. MCTS-RAG -> [MCTS-RAG: Enhancing Retrieval-Augmented Generation with Monte Carlo Tree Search (2503.20757)](https://huggingface.co/papers/2503.20757)  
	Combines RAG with Monte Carlo Tree Search (MCTS) to help small LMs handle complex, knowledge-heavy tasks  
	  
	5. Typed-RAG - > [Typed-RAG: Type-aware Multi-Aspect Decomposition for Non-Factoid Question Answering (2503.15879)](https://huggingface.co/papers/2503.15879)  
	Improves answers on open-ended questions by identifying question types (a debate, personal experience, or comparison) and breaking it down into simpler parts  
	  
	6. MADAM-RAG -> [Retrieval-Augmented Generation with Conflicting Evidence (2504.13079)](https://huggingface.co/papers/2504.13079)  
	A multi-agent system where models debate answers over multiple rounds and an aggregator filters noise and misinformation  
	  
	7. HM-RAG -> [HM-RAG: Hierarchical Multi-Agent Multimodal Retrieval Augmented Generation (2504.12330)](https://huggingface.co/papers/2504.12330)  
	A hierarchical multi-agent RAG framework that uses 3 agents: one to split queries, one to retrieve across multiple data types (text, graphs and web), and one to merge and refine answers  
	  
	8. CDF-RAG -> [CDF-RAG: Causal Dynamic Feedback for Adaptive Retrieval-Augmented Generation (2504.12560)](https://huggingface.co/papers/2504.12560)  
	Works with causal graphs and enables multi-hop causal reasoning, refining queries. It validates responses against causal pathways

	9. NodeRAG -> [https://huggingface.co/papers/2504.11544](https://huggingface.co/papers/2504.11544)  
	    Uses well-designed heterogeneous graph structures and focuses on graph design to ensure smooth integration of graph algorithms. It outperforms GraphRAG and LightRAG on multi-hop and open-ended QA benchmarks
	    
	10. HeteRAG -> [https://huggingface.co/papers/2504.10529](https://huggingface.co/papers/2504.10529)  
	    This heterogeneous RAG framework decouples knowledge chunk representations. It uses multi-granular views for retrieval and concise chunks for generation, along with adaptive prompt tuning
	    
	11. Hyper-RAG -> [https://huggingface.co/papers/2504.08758](https://huggingface.co/papers/2504.08758)  
	    A hypergraph-based RAG method. By capturing both pairwise and complex relationships in domain-specific knowledge, it improves factual accuracy and reduces hallucinations, especially in high-stakes fields like medicine, surpassing Graph RAG and Light RAG. Its lightweight version also doubles retrieval speed

- From “Era of Human Data” to “Era of Experience”
	1. streams of lifelong experience 
	2. sensor‑motor actions
	3. grounded rewards
	4. non‑human modes of reasoning
- [How we build effective agents](https://www.youtube.com/watch?v=D7_ipDqhtwk )
- [AI is Like Cars](https://ozorn.in/blog/ai-cars/)


## 29.04.2025

- AgenticSeek: Private, Local Manus Alternative - [Fosowl/agenticSeek: A open, local Manus AI alternative. No APIs, No $200 monthly bills. Enjoy an autonomous agent that thinks, browses the web, and code for the sole cost of electricity.](https://github.com/Fosowl/agenticSeek)
- A local open source deep research - https://substack.com/redirect/06ab6d6b-e918-42a0-af4e-23bd6cd9e9cc?j=eyJ1IjoiMTg2bzVvIn0.-AuoIYywR1ZESApp8FJseCWwCCZIKj8CtVTdemeZC-Q

## 02.05.2025

- https://github.com/comet-ml/opik
  An open-source LLM evaluation tool used to debug, evaluate, monitor LLM applications, RAG systems, and agentic workflows with comprehensive tracing, automated evaluations, and production-ready dashboards.
- [allenai/OLMoE: OLMoE: Open Mixture-of-Experts Language Models](https://github.com/allenai/OLMoE)
  Fully open, state-of-the-art Mixture of Expert model with 1.3 billion active and 6.9 billion total parameters.
- [Demystifying Verbatim Memorization in Large Language Models](https://ai.stanford.edu/blog/verbatim-memorization/)


## 05.05.2025

- Microsoft Phi 4 Reasoning Models:
	- **Chain-Of-Thought Reasoning**: These models follow a clear, step-by-step approach to problem-solving, making their logic transparent and more reliable compared to other compact models that often rely on quick guesses.
	- **High-Quality Training**: Phi-4 Mini was trained on 1M synthetic math questions from DeepSeek R1. The larger models were trained on curated web content and OpenAI's o3-mini demos.
	- **Big Context Window**: Supports 32K tokens by default and can be extended to 64K, making it well-suited for long documents such as legal cases, financial reports, or dense academic papers.
- Amazon's NOVA premier is built to teach
  ![[Pasted image 20250505093614.png]]


## 06.05.2025

- [HuggingFace Learning](https://huggingface.co/learn) - HuggingFace just dropped 9 new courses to level up your AI skills.
- [This webinar by Stanford introduces agentic language models](https://link.alphasignal.ai/JxcCLM "https://link.alphasignal.ai/JxcCLM"), their usage patterns, applications, best practices, and ethical considerations.
- [WindSurf CEO discusses how they pivoted](https://link.alphasignal.ai/xNkrgV "https://link.alphasignal.ai/xNkrgV") to AI coding tools, outpacing Copilot, and startup-building lessons.
- [YC's guide shows how to use LLMs](https://link.alphasignal.ai/P9mo8n "https://link.alphasignal.ai/P9mo8n") like Claude Code to build, debug, and refactor apps fast.

## 07.05.2025

- [Scaling Long Context and RAG: Insights from Google DeepMind]([Google AI: Release Notes podcast episode on long context](https://blog.google/technology/google-deepmind/release-notes-podcast-long-context/))
  The "Release Notes Podcast: Long Context and RAG" episode by Google Deepmind dives deep into scaling context windows and improving long-context models. Hosted by Logan Kilpatrick, Google DeepMind’s Nikolay Savinov explores key challenges and advancements in this area, with a focus on Retrieval-Augmented Generation (RAG) and long context models.  
  You will learn:
	- Why token count matters and how models handle multi-million-token inputs  
	- The core differences between RAG pipelines and long-context architectures  
	- How DeepMind evaluates long-context recall beyond standard benchmarks  
	- What’s changed since the 1.5 Pro release in terms of attention and inference  
	- Tips for structuring inputs, optimizing infrastructure, and managing cost  
	- Where long context fits into agent architectures and reasoning workflows

- The workflow to make videos: 
	1. GPT-4o wrote the script (I made some tweaks) 
	2. [@krea_ai](https://x.com/krea_ai)generated the starting image 
	3. [@elevenlabsio](https://x.com/elevenlabsio) made the audio
	4. [@hedra_labs](https://x.com/hedra_labs) animated it

## 08.05.2025

- Official inference framework for 1-bit LLMs - https://github.com/microsoft/bitnet
- Olympus: A Universal Task Router for Computer Vision Tasks - https://github.com/yuanze-lin/Olympus
- [What Every AI Engineer Should Know About A2A, MCP & ACP | by Edwin Lisowski | Apr, 2025 | Medium](https://medium.com/@elisowski/what-every-ai-engineer-should-know-about-a2a-mcp-acp-8335a210a742)
  ![[Pasted image 20250508100420.png]]
- [Building News Agents for Daily News Recaps with MCP, Q, and tmux](https://eugeneyan.com/writing/news-agents/)


## 09.05.2025

Build DeepSeek from Scratch

- DeepSeek series introduction: [https://lnkd.in/gRcNE-sg](https://lnkd.in/gRcNE-sg)  
- DeepSeek basics: [https://lnkd.in/gEUzFtrC](https://lnkd.in/gEUzFtrC)  
- Journey of a token into the LLM architecture: [https://lnkd.in/gUnabApX](https://lnkd.in/gUnabApX)  
- Attention mechanism explained in 1 hour: [https://lnkd.in/gSVXDn2e](https://lnkd.in/gSVXDn2e)  
- Self Attention Mechanism - Handwritten from scratch: [https://lnkd.in/gN85qVSK](https://lnkd.in/gN85qVSK)  
- Causal Attention Explained: Don't Peek into the Future: [https://lnkd.in/gNPwCJWT](https://lnkd.in/gNPwCJWT)  
- Multi-Head Attention Visually Explained: [https://lnkd.in/gPr-XrwE](https://lnkd.in/gPr-XrwE)  
- Multi-Head Attention Handwritten from Scratch: [https://lnkd.in/gzb6Xvy6](https://lnkd.in/gzb6Xvy6)  
- Key Value Cache from Scratch: [https://lnkd.in/gn8zgdc7](https://lnkd.in/gn8zgdc7)  
- Multi-Query Attention Explained: [https://lnkd.in/gvt3AyRh](https://lnkd.in/gvt3AyRh)  
- Understand Grouped Query Attention (GQA): [https://lnkd.in/geFFq_95](https://lnkd.in/geFFq_95)  
- Multi-Head Latent Attention From Scratch: [https://lnkd.in/g3z8PkCZ](https://lnkd.in/g3z8PkCZ)  
- Multi-Head Latent Attention Coded from Scratch in Python: [https://lnkd.in/g9drDgGZ](https://lnkd.in/g9drDgGZ)

## 13.05.2025

- [ZeroSearch: Incentivize the Search Capability of LLMs without Searching]([Alibaba-NLP/ZeroSearch: ZeroSearch: Incentivize the Search Capability of LLMs without Searching](https://github.com/Alibaba-nlp/ZeroSearch))
	- We propose ZeroSearch, a novel reinforcement learning framework that incentivizes the capability of LLMs to use a real search engine with simulated searches during training.
	- Through supervised fine-tuning, we transform the LLM into a retrieval module capable of generating both relevant and noisy documents in response to a query. We further introduce a curriculum rollout mechanism to progressively elicit the model’s reasoning ability by exposing it to increasingly challenging retrieval scenarios.
	- We conduct extensive experiments on both in-domain and out-of-domain datasets. Results show that ZeroSearch outperforms real search engine-based models while incurring zero API cost. Moreover, it generalizes well across both base and instruction-tuned LLMs of various sizes and supports different reinforcement learning algorithms.
- [Building LLMs from the Ground Up: A 3-hour Coding Workshop](https://magazine.sebastianraschka.com/p/building-llms-from-the-ground-up)
- [**Hugging Face has released nanoVLM**](https://huggingface.co/lusxvr/nanoVLM-222M), a compact PyTorch-based framework that lets you train a vision-language model from scratch in just 750 lines of code. It’s designed to be readable, modular, and easy to extend, making it ideal for learning, prototyping, or research. The model uses a SigLIP-B/16 vision encoder and a SmolLM2 language decoder. All code is open on GitHub and the Hugging Face Hub.
- [**llama.cpp now supports vision input**](https://github.com/ggml-org/llama.cpp/blob/master/docs/multimodal.md), letting you run multimodal models locally using `llama-mtmd-cli` or `llama-server`. Models like Gemma 3, Qwen2.5 VL, and SmolVLM are already supported, and you can enable vision with a simple `-hf` flag or load your own projector file if needed. What’s nice is that vision is now built directly into the server—no extra hacks or plugins. This makes it easier to manage, faster to update, and cleaner to use across different tools.

## 14.05.2025

- Sakana AI unveiled [Continuous Thought Machines (CTMs)]([Continuous Thought Machines](https://pub.sakana.ai/ctm/)), a new type of model that makes AI more brain-like by allowing it to “think” step-by-step over time instead of making instant decisions like current AI systems do.

	**Example code:** [continuous-thought-machines/examples/01_mnist.ipynb at main · SakanaAI/continuous-thought-machines](https://github.com/SakanaAI/continuous-thought-machines/blob/main/examples/01_mnist.ipynb)
### 1. **Internal Recurrence (aka "Thought Steps")**

	Think of this as the model taking time to **internally reflect or think**, even if the input is static (like an image). Each "tick" is one such **thought step**.
	
	- Unlike RNNs or Transformers which move through time/data,
	    
	- CTM has **internal ticks** (e.g., T=75), meaning it reflects **T times** internally on a given input before responding.
	
	 **Analogy: Like solving a maze — you stop, stare at the image, and think step-by-step what path to take before actually moving.**

### 2. **Neuron-Level Models (Private MLPs per Neuron)**
	
	Each neuron in CTM **remembers the last M steps** of its own activity and has a **private MLP** to decide its next activation. This is **very different** from traditional models where all neurons share the same update rules.
	
	- Input goes into a **"synapse" MLP** to produce pre-activations.
	    
	- Each neuron takes a **history of its pre-activations** and processes it using its own MLP to get its output (post-activation).
	  
 	**Analogy: Imagine each neuron is a tiny agent with its own memory and rulebook. It watches its past behavior and decides what to do next, independently.**

### 3. **Synchronization as the Representation**

	Instead of just using the current neuron activations, CTM **tracks how neuron activations synchronize over time**.
	
	- At each tick, it computes **how pairs of neurons are co-activated** over time.
	    
	- This creates a **synchronization matrix**, which becomes the actual representation used to **read data** (attention) and **make predictions**.

	**Analogy: Imagine a team solving a puzzle. The more certain pairs of people "think in sync" over time, the more important their coordination is. That synchronization becomes the team's strategy.**

### Pseudocode

```
### Step 1 to T (Internal Ticks, like 75 thought steps):

At each tick:

1. **Build pre-activations** using the synapse MLP based on current state and attention over image.
    
2. Each neuron:
    
    - Looks at its own history of pre-activations.
        
    - Runs its **own private MLP** to decide its new post-activation.
        
3. Collect post-activations for all neurons → build a time history.
    
4. Compute **synchronization matrix** (how neuron pairs are co-active).
    
5. Use part of synchronization matrix to:
    
    - Read data (attention queries)
        
    - Predict output logits (dog/cat probabilities).
        
6. Store prediction & certainty for current tick.
    

Repeat this T times.
```

### Final Step: Choose Which Tick(s) to Learn From

- Compute loss and certainty at each tick.
    
- Instead of just using the final tick, use:
    
    - `t₁ = tick with lowest loss`
        
    - `t₂ = tick with highest certainty`
        
- Final loss: average of these two → encourages learning from both strong predictions and confident thoughts.


## 15.05.2025

- As large language models (LLMs) become more deeply embedded in applications, ensuring their safe and secure operation is critical. Meta's [**LlamaFirewall**]([PurpleLlama/LlamaFirewall at main · meta-llama/PurpleLlama](https://github.com/meta-llama/PurpleLlama/tree/main/LlamaFirewall)) is an open-source guardrail framework designed to serve as a final layer of defense against various security risks that come with deploying AI agents. It addresses challenges such as prompt injection, agent misalignment, and unsafe code generation, providing developers with the necessary tools to build robust and secure AI systems.

## 20.05.2025

- [Model Context Protocol (MCP) Course - Hugging Face MCP Course](https://huggingface.co/learn/mcp-course/unit0/introduction)). Learn MCP architecture, SDKs, and end-to-end application building. Gain hands-on experience with real-world use cases, community projects, and partner tools. Earn a certificate by completing assignments and join the active community for ongoing support.

## 23.05.2025

- [The State of LLM Reasoning Model Inference](https://magazine.sebastianraschka.com/p/state-of-llm-reasoning-and-inference-scaling) An article that explores recent research advancements in reasoning-optimized LLMs, with a particular focus on inference-time compute scaling.
- [Why We Think | Lil'Log](https://lilianweng.github.io/posts/2025-05-01-thinking/) Lilian Weng explores how giving LLMs extra "thinking time" and enabling them to show intermediate steps (like Chain-of-Thought) significantly improves their ability to solve complex problems.
- https://github.com/lmcache/lmcache An LLM serving engine extension to reduce TTFT and increase throughput, especially under long-context scenarios.

## 28.05.2025

- **BAGEL** is an open-source foundation model trained on diverse interleaved multimodal data, outperforming peers in reasoning, manipulation, and understanding → [read the paper](https://link.mail.beehiiv.com/ss/c/u001.24PJKv5ZY5jFY09zxUFvCeT_AGjxQa6bD3cNDicyXK2dYTBT1Xn3-2brjUomfXWrccishoDVQNZNITR4hiK7rckHdCVRJJQU0BkLCPkCsuTkj0whdTHY9SmypfuTtC3iFXrSTEG33EMt3pOOAzDRbCyj9iaLKx9PztMbsIGOQQ5aO5BeOqW2mjShYHvFFBIz9PhtWOaEcJpRxtFCBh_wX9_9pgMZJuZOwPqiSH1zqtfmBrDkp3zphFk8GGlpIoMisNd_cVFDjHCSnTcaVl03Eg/4gu/S3TZHJPrRHyiKLYBVVpQFw/h30/h001.h-ltbvUwMd6Yp2iwXVagnHVQpKQsZvjswSMz3Yxsln0 "https://link.mail.beehiiv.com/ss/c/u001.24PJKv5ZY5jFY09zxUFvCeT_AGjxQa6bD3cNDicyXK2dYTBT1Xn3-2brjUomfXWrccishoDVQNZNITR4hiK7rckHdCVRJJQU0BkLCPkCsuTkj0whdTHY9SmypfuTtC3iFXrSTEG33EMt3pOOAzDRbCyj9iaLKx9PztMbsIGOQQ5aO5BeOqW2mjShYHvFFBIz9PhtWOaEcJpRxtFCBh_wX9_9pgMZJuZOwPqiSH1zqtfmBrDkp3zphFk8GGlpIoMisNd_cVFDjHCSnTcaVl03Eg/4gu/S3TZHJPrRHyiKLYBVVpQFw/h30/h001.h-ltbvUwMd6Yp2iwXVagnHVQpKQsZvjswSMz3Yxsln0") __
-  **Claude Opus 4 & Sonnet 4 by Anthropic** introduces extended thinking and hybrid modes that allow parallel tool use, memory retention via local files, and state-of-the-art results on SWE-bench and agent workflows → [read more](https://link.mail.beehiiv.com/ss/c/u001.jn0edDRfKFDgePDQMdc7OBn3ovPb9Veem6A62MTB6HqTrfumNGH_j7hoTqsDVmwwCARvr1XxOhL-qprpjJoOAZemZzajQRxKq_CjCzOi4YmLl8fo_ECqahxSVS89pQ8r-njhtc6bt8N6BIT6XC-ifyrvM3vbiiAPvRt1CI77RY3P1QahnpcBc2WcsPI3_9mgW41Q_2hHtNkq_NthvvhkQrZgcB7WCDsjShRhZ3pwWLFg4ZqLDBIrRufXZG4lKBge595eiIAWlr8o4nyTE1DOnw/4gu/S3TZHJPrRHyiKLYBVVpQFw/h31/h001.JXLHHipKBBUftsSRLjpYk8clizFe9uLMDi8PPvm_ngM "https://link.mail.beehiiv.com/ss/c/u001.jn0edDRfKFDgePDQMdc7OBn3ovPb9Veem6A62MTB6HqTrfumNGH_j7hoTqsDVmwwCARvr1XxOhL-qprpjJoOAZemZzajQRxKq_CjCzOi4YmLl8fo_ECqahxSVS89pQ8r-njhtc6bt8N6BIT6XC-ifyrvM3vbiiAPvRt1CI77RY3P1QahnpcBc2WcsPI3_9mgW41Q_2hHtNkq_NthvvhkQrZgcB7WCDsjShRhZ3pwWLFg4ZqLDBIrRufXZG4lKBge595eiIAWlr8o4nyTE1DOnw/4gu/S3TZHJPrRHyiKLYBVVpQFw/h31/h001.JXLHHipKBBUftsSRLjpYk8clizFe9uLMDi8PPvm_ngM")
-  **Claude Code by Anthropic**  
    Now GA with IDE integrations, background GitHub tasks, and a full SDK for custom agents. Extends Claude’s capabilities into hands-on dev tooling → [read more](https://link.mail.beehiiv.com/ss/c/u001.jn0edDRfKFDgePDQMdc7OBn3ovPb9Veem6A62MTB6HqTrfumNGH_j7hoTqsDVmwwCARvr1XxOhL-qprpjJoOAZemZzajQRxKq_CjCzOi4YmLl8fo_ECqahxSVS89pQ8r-njhtc6bt8N6BIT6XC-ifyrvM3vbiiAPvRt1CI77RY3P1QahnpcBc2WcsPI3_9mgW41Q_2hHtNkq_NthvvhkQh9EImYzsB_uHIOxeq_PkiV5mypfxSUyiLeYENhOIri8tie21OTunejyZiF8iVq3kg/4gu/S3TZHJPrRHyiKLYBVVpQFw/h32/h001.kdCVvL8zXsaR0O_5oS7kRgQ2seg70oYkaS6ZbjIZSMo "https://link.mail.beehiiv.com/ss/c/u001.jn0edDRfKFDgePDQMdc7OBn3ovPb9Veem6A62MTB6HqTrfumNGH_j7hoTqsDVmwwCARvr1XxOhL-qprpjJoOAZemZzajQRxKq_CjCzOi4YmLl8fo_ECqahxSVS89pQ8r-njhtc6bt8N6BIT6XC-ifyrvM3vbiiAPvRt1CI77RY3P1QahnpcBc2WcsPI3_9mgW41Q_2hHtNkq_NthvvhkQh9EImYzsB_uHIOxeq_PkiV5mypfxSUyiLeYENhOIri8tie21OTunejyZiF8iVq3kg/4gu/S3TZHJPrRHyiKLYBVVpQFw/h32/h001.kdCVvL8zXsaR0O_5oS7kRgQ2seg70oYkaS6ZbjIZSMo")
-  **Gemma 3n by Google** introduces a mobile-first, multimodal model designed for local inference with a 4B memory footprint and dynamic submodel creation for latency-quality tradeoffs → [read more](https://link.mail.beehiiv.com/ss/c/u001.uS3tkyBVoUvkxCpW2qTio96uL2o4NBiXYCla1cxC_5k9h-o1goxJbHEBxvS6txBqYZZt3pJf_wecC0CbqjpnQafjRS_9jMprHAf8dgAQ6s9UAFThJEuNVX-eP1m8X3j6C-c_6W4eYLRQSPvwrWNCvqdSIA8_WNzuhRGRrz8jr_gdMNHpuuoqn9zX117M57XLqg9lQ6CTV3e9W4dldJ1Yhi1KlQyPp8XmEeo66KLZcaUBe6MX4XqCYQ6mRPf7FaXtkRcfawOomUiAGu9DHkVE9kgqxaJ6gk21Xnb8sK8bGfU/4gu/S3TZHJPrRHyiKLYBVVpQFw/h33/h001.h5kfMpkd17aAJfcDCPmd-iqwb72JNjPbQIMS9vZ31sY "https://link.mail.beehiiv.com/ss/c/u001.uS3tkyBVoUvkxCpW2qTio96uL2o4NBiXYCla1cxC_5k9h-o1goxJbHEBxvS6txBqYZZt3pJf_wecC0CbqjpnQafjRS_9jMprHAf8dgAQ6s9UAFThJEuNVX-eP1m8X3j6C-c_6W4eYLRQSPvwrWNCvqdSIA8_WNzuhRGRrz8jr_gdMNHpuuoqn9zX117M57XLqg9lQ6CTV3e9W4dldJ1Yhi1KlQyPp8XmEeo66KLZcaUBe6MX4XqCYQ6mRPf7FaXtkRcfawOomUiAGu9DHkVE9kgqxaJ6gk21Xnb8sK8bGfU/4gu/S3TZHJPrRHyiKLYBVVpQFw/h33/h001.h5kfMpkd17aAJfcDCPmd-iqwb72JNjPbQIMS9vZ31sY")
- **Reward Reasoning Model by Microsoft Research and Tsinghua University** proposes chain-of-thought reward modeling with test-time compute adaptation, enabling better alignment through self-evolved reasoning → [read the paper](https://link.mail.beehiiv.com/ss/c/u001.24PJKv5ZY5jFY09zxUFvCeT_AGjxQa6bD3cNDicyXK1ctmw5V2JAr7p6ANTLUGCGUEj9qeoMifCDT4FH3iLP3iX24LzxbVEU6UYaZtMwBoBnLLYZ8cQUz9ntDGmAWN9Z_-7N8PI8L7KHMMTOdD2LVmw9E2BYgvSQO-rqg6IHDLHMrBUkPnsAVavSdNIvDEPxT26cFeIIMbrMOFuAb3fxAWRhHBeWAJZmKP9g1H_CDQZCFSN59pI4tuwe9wJtIg2uFXS9dAraOzbXuprDLprRPQ/4gu/S3TZHJPrRHyiKLYBVVpQFw/h34/h001.X3jWM4aAus3J4HYyHNloSSgAK4kjQTxk9zrvghitOIA "https://link.mail.beehiiv.com/ss/c/u001.24PJKv5ZY5jFY09zxUFvCeT_AGjxQa6bD3cNDicyXK1ctmw5V2JAr7p6ANTLUGCGUEj9qeoMifCDT4FH3iLP3iX24LzxbVEU6UYaZtMwBoBnLLYZ8cQUz9ntDGmAWN9Z_-7N8PI8L7KHMMTOdD2LVmw9E2BYgvSQO-rqg6IHDLHMrBUkPnsAVavSdNIvDEPxT26cFeIIMbrMOFuAb3fxAWRhHBeWAJZmKP9g1H_CDQZCFSN59pI4tuwe9wJtIg2uFXS9dAraOzbXuprDLprRPQ/4gu/S3TZHJPrRHyiKLYBVVpQFw/h34/h001.X3jWM4aAus3J4HYyHNloSSgAK4kjQTxk9zrvghitOIA")
-  **R3: Robust Rubric-Agnostic Reward Models** introduces interpretable, generalizable reward modeling without fixed rubrics, improving alignment flexibility and transparency → [read the paper](https://link.mail.beehiiv.com/ss/c/u001.24PJKv5ZY5jFY09zxUFvCeT_AGjxQa6bD3cNDicyXK3Jx60p6INCw65aVmdX86MgQ9Jk4nwEHKa6X2JYv6uc0aSfMy4ymWjitovLlj1UnOA8m5Vz821-e1nGuDnWmrb_EspXFKaI-T7Q4V6v56-wlAl9mT8Z2s0vy_keJq-Q_KrxeRZ7OjqY0yJUmr4HHPaAP2UCfVyVpXF2p8XtQHPSFqLgcECjyuFAzWBX7wnMYpegVxLML7U3XyYaKOBISkAt24dRbtxjbNpqAGixQ-I6-g/4gu/S3TZHJPrRHyiKLYBVVpQFw/h35/h001.wS9OKegOW7BZFhmVG3nPcEqVGg9hZqzLvQnaxtVg2zU "https://link.mail.beehiiv.com/ss/c/u001.24PJKv5ZY5jFY09zxUFvCeT_AGjxQa6bD3cNDicyXK3Jx60p6INCw65aVmdX86MgQ9Jk4nwEHKa6X2JYv6uc0aSfMy4ymWjitovLlj1UnOA8m5Vz821-e1nGuDnWmrb_EspXFKaI-T7Q4V6v56-wlAl9mT8Z2s0vy_keJq-Q_KrxeRZ7OjqY0yJUmr4HHPaAP2UCfVyVpXF2p8XtQHPSFqLgcECjyuFAzWBX7wnMYpegVxLML7U3XyYaKOBISkAt24dRbtxjbNpqAGixQ-I6-g/4gu/S3TZHJPrRHyiKLYBVVpQFw/h35/h001.wS9OKegOW7BZFhmVG3nPcEqVGg9hZqzLvQnaxtVg2zU")
- **Panda** is a pretrained model on synthetic chaotic systems that generalizes to real-world dynamics, even predicting PDEs with no retraining → [read the paper](https://link.mail.beehiiv.com/ss/c/u001.24PJKv5ZY5jFY09zxUFvCeT_AGjxQa6bD3cNDicyXK0ITBdEQq1Z_QuVlxFx0E37sjThHN7OVqjOayhV_fhpy0wi5OLZ674uKDv26E_rZGrMqk8688X7GzfK-Gb_i6QO4gFSMLQNKu4UV-nQ8GoleFWDAHvUmvgIUcEfLvYd95ZH9Kpa69PNdluayvoPRr9MNFiOz3ucIR6JSQ5REK2kYPvPV_HiaN-DV9MNm2qOKDmw-iVq-26tzmR9nuVmMnEGIp9hynvidrcFWP8c9M6QiA/4gu/S3TZHJPrRHyiKLYBVVpQFw/h36/h001.JFVoVg1f0a_9XUKAvCvH0r8oeW5KgLDs3674wqw-qjA "https://link.mail.beehiiv.com/ss/c/u001.24PJKv5ZY5jFY09zxUFvCeT_AGjxQa6bD3cNDicyXK0ITBdEQq1Z_QuVlxFx0E37sjThHN7OVqjOayhV_fhpy0wi5OLZ674uKDv26E_rZGrMqk8688X7GzfK-Gb_i6QO4gFSMLQNKu4UV-nQ8GoleFWDAHvUmvgIUcEfLvYd95ZH9Kpa69PNdluayvoPRr9MNFiOz3ucIR6JSQ5REK2kYPvPV_HiaN-DV9MNm2qOKDmw-iVq-26tzmR9nuVmMnEGIp9hynvidrcFWP8c9M6QiA/4gu/S3TZHJPrRHyiKLYBVVpQFw/h36/h001.JFVoVg1f0a_9XUKAvCvH0r8oeW5KgLDs3674wqw-qjA")
- **AceReason-Nemotron by Nvidia** demonstrates that large-scale RL can outperform distillation in reasoning for both math and code, using curriculum-style training → [read the paper](https://link.mail.beehiiv.com/ss/c/u001.ttmSb5K5OX4bT3feQaFiKyYDNZvaMc5ib6nNG2vNbYUSZmfWjrtiJcPvXsYffKVA2ol9IXj7vDYSIJJAecGU9aar-Oz0aqAxKdACWNHu9Y79daJqDHlZJjtPsMCeCgZpuqWrXgzTmqHyN4pdA-_sR0zLY1mOPpy_nMyS5LhoTZ_Y_1cGn0lHH3Byd3wyHzdu7ACexquUwAr1L9JWU1q5QOXKEwmw9KXVvehM2cMJ4tpJUkh50IgO5dJArPAJYxeZN7ij03xPoaPMtrSIW5MGig/4gu/S3TZHJPrRHyiKLYBVVpQFw/h37/h001.KWywQa0nutzx9SRpSmL5ccumoJT3KT8T8_YB7GJFkHs "https://link.mail.beehiiv.com/ss/c/u001.ttmSb5K5OX4bT3feQaFiKyYDNZvaMc5ib6nNG2vNbYUSZmfWjrtiJcPvXsYffKVA2ol9IXj7vDYSIJJAecGU9aar-Oz0aqAxKdACWNHu9Y79daJqDHlZJjtPsMCeCgZpuqWrXgzTmqHyN4pdA-_sR0zLY1mOPpy_nMyS5LhoTZ_Y_1cGn0lHH3Byd3wyHzdu7ACexquUwAr1L9JWU1q5QOXKEwmw9KXVvehM2cMJ4tpJUkh50IgO5dJArPAJYxeZN7ij03xPoaPMtrSIW5MGig/4gu/S3TZHJPrRHyiKLYBVVpQFw/h37/h001.KWywQa0nutzx9SRpSmL5ccumoJT3KT8T8_YB7GJFkHs")
-  **Neurosymbolic Diffusion Models** improves symbolic reasoning accuracy by modeling dependencies through discrete diffusion, achieving better calibration and generalization → [read the paper](https://link.mail.beehiiv.com/ss/c/u001.24PJKv5ZY5jFY09zxUFvCeT_AGjxQa6bD3cNDicyXK34I-pksqG5QNbt7kA7CmYMW0Dh0zfT8TXgOmZU0_2FgGR4SvJNaDlViukxvDYTR3lVXjHTP18Ad7qm8Hh6nENXu1xti6OU62C13Eiyx2rVi-Yrenb7qdwDxA0SY7Kn7DYn_2w2glzVvtKKZKSqdCpu4RXrXg2IfUYJ26aJL3vXd_SKjaFCDcqnFiOZ3eETWvWBVFwAEMTB4fnJG2YASwqsghym-Z-e8NUZNZTKofhzjg/4gu/S3TZHJPrRHyiKLYBVVpQFw/h38/h001.c6x5I8Y2tTmMlCjLmnBRezzUbqQtAM7hVkn844eRgw8 "https://link.mail.beehiiv.com/ss/c/u001.24PJKv5ZY5jFY09zxUFvCeT_AGjxQa6bD3cNDicyXK34I-pksqG5QNbt7kA7CmYMW0Dh0zfT8TXgOmZU0_2FgGR4SvJNaDlViukxvDYTR3lVXjHTP18Ad7qm8Hh6nENXu1xti6OU62C13Eiyx2rVi-Yrenb7qdwDxA0SY7Kn7DYn_2w2glzVvtKKZKSqdCpu4RXrXg2IfUYJ26aJL3vXd_SKjaFCDcqnFiOZ3eETWvWBVFwAEMTB4fnJG2YASwqsghym-Z-e8NUZNZTKofhzjg/4gu/S3TZHJPrRHyiKLYBVVpQFw/h38/h001.c6x5I8Y2tTmMlCjLmnBRezzUbqQtAM7hVkn844eRgw8")
- **MMaDA** combines diffusion-based reasoning with unified chain-of-thought fine-tuning and a new RL algorithm (UniGRPO), outperforming SDXL and LLaMA-3 in multiple tasks → [read the paper](https://link.mail.beehiiv.com/ss/c/u001.24PJKv5ZY5jFY09zxUFvCeT_AGjxQa6bD3cNDicyXK2ih9kx_Gtmx649oZk2aknxlx21Q6BLuMAS1hLLhf9CvB_FOLcjEZDEz81wK6pi3b32NSYIGTTru5Ug08RIQBsNhm_ZjcprasqrtdWbMmRTUUTkZIPqkGSvQU7a6Wm8Qb0__IcIjViugZY464DMdODZJJFF7pLuZPyjEGf-VfIT09GcS2LB6IIKZpahc76LWH3c1uj6UntrHPRhJhriEdaDIqeunJX-OkoB4IHVwEc2Nw/4gu/S3TZHJPrRHyiKLYBVVpQFw/h39/h001.aN2xs0c0yXBwRQF9J_kYdB35CynjVDgeA6ET2uvJvVk "https://link.mail.beehiiv.com/ss/c/u001.24PJKv5ZY5jFY09zxUFvCeT_AGjxQa6bD3cNDicyXK2ih9kx_Gtmx649oZk2aknxlx21Q6BLuMAS1hLLhf9CvB_FOLcjEZDEz81wK6pi3b32NSYIGTTru5Ug08RIQBsNhm_ZjcprasqrtdWbMmRTUUTkZIPqkGSvQU7a6Wm8Qb0__IcIjViugZY464DMdODZJJFF7pLuZPyjEGf-VfIT09GcS2LB6IIKZpahc76LWH3c1uj6UntrHPRhJhriEdaDIqeunJX-OkoB4IHVwEc2Nw/4gu/S3TZHJPrRHyiKLYBVVpQFw/h39/h001.aN2xs0c0yXBwRQF9J_kYdB35CynjVDgeA6ET2uvJvVk")
- **UniVG-R1** reinforces visual grounding with CoT and difficulty-aware reinforcement learning, achieving top scores on multiple video/image grounding tasks → [read the paper](https://link.mail.beehiiv.com/ss/c/u001.24PJKv5ZY5jFY09zxUFvCeT_AGjxQa6bD3cNDicyXK0XoIjC26TbNLbri2CPclmMuaqzwIdycGmSJgFDZsiyPo6DQamEV6NUyS1mRxnETLndYFApBFnsS3TCghhs9zMPcbdaI-zrbXf94XkuhWNz7P7ORgCvMgL_Qa7nXioZcJ7TqqoQ1y1nsx9x24_7OMHFqgd5ciEYpKx8k9TUv8PU3rDsEvIumBHxsW-AttijKnGjzEKfv7sEhVr8vo-z9ISVHSbaRFd3nng9LJnttIbyEw/4gu/S3TZHJPrRHyiKLYBVVpQFw/h40/h001.ObUvOhojS_yYRo-a4R302_YDnX8RowlErTXbD88NZ6w "https://link.mail.beehiiv.com/ss/c/u001.24PJKv5ZY5jFY09zxUFvCeT_AGjxQa6bD3cNDicyXK0XoIjC26TbNLbri2CPclmMuaqzwIdycGmSJgFDZsiyPo6DQamEV6NUyS1mRxnETLndYFApBFnsS3TCghhs9zMPcbdaI-zrbXf94XkuhWNz7P7ORgCvMgL_Qa7nXioZcJ7TqqoQ1y1nsx9x24_7OMHFqgd5ciEYpKx8k9TUv8PU3rDsEvIumBHxsW-AttijKnGjzEKfv7sEhVr8vo-z9ISVHSbaRFd3nng9LJnttIbyEw/4gu/S3TZHJPrRHyiKLYBVVpQFw/h40/h001.ObUvOhojS_yYRo-a4R302_YDnX8RowlErTXbD88NZ6w").
- **Web-Shepherd** introduces a step-level reward model for web navigation, significantly improving trajectory evaluation accuracy and cost-efficiency → [read the paper](https://link.mail.beehiiv.com/ss/c/u001.24PJKv5ZY5jFY09zxUFvCeT_AGjxQa6bD3cNDicyXK2L5Jv_fr3BCDOhTBPwk1QtsBo7QsyG4cV5KCN8ksfluMwgRSQ2i9usXf0fsttFk9RCXWx6EX_tu6Yjr6Tjc1Y9df7P2N3LR0VmBvk_M6EWK0tYEaQqq-_ZYirShGKbsa4Bcr42M5U6BWMaafKxi_Ax634f2L7BhcGQf7sWahQAmU2BEn83grcbAsADrrLPmxsMVxofltvT_tbQWAmM4zHDRXFP95_y1Aw3NyqY4Wl4iQ/4gu/S3TZHJPrRHyiKLYBVVpQFw/h41/h001.UexzpDw2g3DTK1pRApuzytPNd1SUD0Vc2g5_ycuxvV0 "https://link.mail.beehiiv.com/ss/c/u001.24PJKv5ZY5jFY09zxUFvCeT_AGjxQa6bD3cNDicyXK2L5Jv_fr3BCDOhTBPwk1QtsBo7QsyG4cV5KCN8ksfluMwgRSQ2i9usXf0fsttFk9RCXWx6EX_tu6Yjr6Tjc1Y9df7P2N3LR0VmBvk_M6EWK0tYEaQqq-_ZYirShGKbsa4Bcr42M5U6BWMaafKxi_Ax634f2L7BhcGQf7sWahQAmU2BEn83grcbAsADrrLPmxsMVxofltvT_tbQWAmM4zHDRXFP95_y1Aw3NyqY4Wl4iQ/4gu/S3TZHJPrRHyiKLYBVVpQFw/h41/h001.UexzpDw2g3DTK1pRApuzytPNd1SUD0Vc2g5_ycuxvV0")
- **Toto** by Datadog a decoder-only foundation model with 151 million parameters for time series forecasting using observability metrics → [read the paper](https://link.mail.beehiiv.com/ss/c/u001.24PJKv5ZY5jFY09zxUFvCeT_AGjxQa6bD3cNDicyXK3XBDYR8BWyhS2V04LjqemC-mFZGgQcpcEfFcELUrpa3yKGW-bnkCt32g0fFdg-_dpk6HlDv20Th15ufbKyHBhqcqLfL26PzqPJeYosZM3c4AN1oZ4VctiGCMbXh0wBZaskMTRpd4vjWKof38ncA5jS0PcWIufCKjKi0i7lhfOHL-614TLpTs8-Y1j60AXtsvnY9MD8Yvlgm4pRSl7Zr42KkYJcrLOpBJHWmphhtL39zw/4gu/S3TZHJPrRHyiKLYBVVpQFw/h42/h001.PGO5UWY4kjxQ4f6b2CT9_tEsRYSuq9k9IYtEmjAlhr4 "https://link.mail.beehiiv.com/ss/c/u001.24PJKv5ZY5jFY09zxUFvCeT_AGjxQa6bD3cNDicyXK3XBDYR8BWyhS2V04LjqemC-mFZGgQcpcEfFcELUrpa3yKGW-bnkCt32g0fFdg-_dpk6HlDv20Th15ufbKyHBhqcqLfL26PzqPJeYosZM3c4AN1oZ4VctiGCMbXh0wBZaskMTRpd4vjWKof38ncA5jS0PcWIufCKjKi0i7lhfOHL-614TLpTs8-Y1j60AXtsvnY9MD8Yvlgm4pRSl7Zr42KkYJcrLOpBJHWmphhtL39zw/4gu/S3TZHJPrRHyiKLYBVVpQFw/h42/h001.PGO5UWY4kjxQ4f6b2CT9_tEsRYSuq9k9IYtEmjAlhr4")

## 29.05.2025

- **How to build almost ANY LiDAR Object Detector!**
  And it's about building detector frameworks, rather than detector algorithms.
  
  **Take for example, VoxelNet.**  
  This pioneer approach comes directly from Apple's Project Titan Lab, and most of the algorithms you see today come partly from this one.
  
  **How does VoxelNet work?** it "voxelizes" the point cloud (transforms the points into minecraft voxels), and then uses 3D Convolutional Neural Networks to learn the features and process them.
  
  But __this approach is slow__.
  
  And this is when, in 2018, Holger Caesar and his team of researchers invented another algorithm: Point Pillars.
  
  This approach makes VoxelNet real-time.
  
  How?
  
  By converting the 3D problem (3D Voxels, 3D CNNs, etc...), into a 2D problem (2D Pillars, 2D CNNs, ...). Like a miracle, the pillar technique worked and made the algorithm real-time.
  
  But one question remains...  
  **How do you learn something as wide as 3D Deep Learning?**
  
  Things like **Voxelization** (VFE) and **3D CNNs** (3D Backbones) used in VoxelNet, but also 2D Transformations (used in PointPillars), or **PointNets** (PFE), and others..
  
  **The truth is that the field was essentially using and re-using the same 11 Blocks over and over again.**   
  And that using these 11 blocks, you could build almost ANY architecture!
  
  ![[1e3f1e2a-26aa-4e88-968b-fc5127480706.gif]]
  
  Almost every algorithm you will see use a combination of these 11 blocks. Whether it's VoxelNet, PointPillars, SECOND, or more recent ones.


## 02.06.2025

- [How to use LLMs better](https://learnhowtolearn.org/wiki/how-to-use-llms-better/)
- [Anthropic open-sources its circuit tracing tools](https://github.com/safety-research/circuit-tracer) to reveal how LLMs make decisions.

## 05.06.2025

- [RLHF 101: A Technical Tutorial on Reinforcement Learning from Human Feedback – Machine Learning Blog | ML@CMU | Carnegie Mellon University](https://blog.ml.cmu.edu/2025/06/01/rlhf-101-a-technical-tutorial-on-reinforcement-learning-from-human-feedback/)

## 11.06.2025

- [Why DeepSeek models](https://link.mail.beehiiv.com/ss/c/u001.22XVe7hOOQo4HoFgEcBa7zqumjfm_NASJ7K6cNJWrimeYgKQX57beE6ymTe2h8WUUkvP0Txg_HWDBfvk4UNlSLkMrgmkzpMFz-VFlOsyLw-Kj1fgxwq-vcDKc7lOWNYSAXrLnGCFnibjA-aSrOm2FPg-ADuLZz2RYjDbHW0_wj0FlufiGTWAovvxR84VmLTyS-Tz37kKya-m26BYMfQdsCEBszwgPzW3gFclqUTcjpMCEj1H8_EZPVkKKpGAUjD1oTQOcxQre-epCtmZ1dqkzzWzDvNGu_dre9nGd-c0yaM/4h8/y1Tk4PPFTv-mXy2JviCycw/h33/h001.6STPmKkDQU2KPNIU02FDly1xEiWcRPNFQaKNbxHgObY "https://link.mail.beehiiv.com/ss/c/u001.22XVe7hOOQo4HoFgEcBa7zqumjfm_NASJ7K6cNJWrimeYgKQX57beE6ymTe2h8WUUkvP0Txg_HWDBfvk4UNlSLkMrgmkzpMFz-VFlOsyLw-Kj1fgxwq-vcDKc7lOWNYSAXrLnGCFnibjA-aSrOm2FPg-ADuLZz2RYjDbHW0_wj0FlufiGTWAovvxR84VmLTyS-Tz37kKya-m26BYMfQdsCEBszwgPzW3gFclqUTcjpMCEj1H8_EZPVkKKpGAUjD1oTQOcxQre-epCtmZ1dqkzzWzDvNGu_dre9nGd-c0yaM/4h8/y1Tk4PPFTv-mXy2JviCycw/h33/h001.6STPmKkDQU2KPNIU02FDly1xEiWcRPNFQaKNbxHgObY") are good at reasoning
- [SkyReels-V2](https://github.com/SkyworkAI/SkyReels-V2) An open-source video generation tool that generates cinematic videos. Supports script-to-video, lip-sync, music, LoRA effects, and storyboards. Runs locally and doesn’t enforce any length restrictions.

## 17.06.2025

- [Local Deep Researcher](https://github.com/langchain-ai/local-deep-researcher) This walkthrough shows how to run DeepSeek-R1 locally using Ollama, load its 14B distilled model, and test JSON-mode outputs. You’ll build a self-contained research agent that performs web search, summarization, and iterative reflection.
- [How to Choose Large Language Models: A Developer’s Guide to LLMs](https://www.youtube.com/watch?v=pYax2rupKEY) Learn how to evaluate LLMs using real-world benchmarks, open-source leaderboards, and your own data. This guide compares proprietary and open models, shows how to run Granite with Ollama, and walks through RAG setups.

## 18.06.2025

- Sakana’s new [text-to-LoRA tool](https://github.com/SakanaAI/text-to-lora) lets you customize AI models by typing what you want it to be good at, like “help with math problems” or “write marketing copy,” and it creates a specialized version in seconds ([paper](https://arxiv.org/abs/2506.06105)).
- 

  
  
  