
# This Week's Top AI/ML Research Papers

#### Vinod

---

#### Transformers without normalization

::: grid
:::: grid-item
**Transformers can achieve or surpass normalized performance using a simple technique called Dynamic Tanh (DyT), replacing normalization layers with an element-wise operation inspired by tanh-like mappings observed in layer norm, validated across various tasks in computer vision and LLMs.**
::::
:::: grid-item
![[Pasted image 20250325101836.png]]
::::
:::



![[Pasted image 20250325101836.png]]





